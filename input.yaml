# Input file

project:
  name: "Linear-Advection_1D1d u(x,t), f(x,t) Varying BC and IC"
  status: "sota" 
  info-techniques: 
    Group I:
      Non-Dimensionalization: true
      Adaptive sampling with in the Mesh: true
      Activation_Tanh: true
      Xavier_init: true
      Exponential decay + Optimizer scheduler: false 
      Loss Balancing: 
        Scheme_no_weights: true
        Scheme_fixed_weights: false
        Scheme_data_guided_weights: false
        Scheme_ntk_guided_weights: false
      Arch:
        MLP: true
        Modified MLP:  false
        Modified Deeponet: false
      Increasing_Train_dataset: false
   

dataset:
  path: '.dataset'
  generate: false # true or false
  processing: false # true or false
  train_fraction: 0.68
  # val_fraction: 0.02
  test_fraction: 0.3 
  varying_param: [0.5,0.6,0.7,0.8,0.9,1.0,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2.0,0.56,1.25,1.95] # parameter c
  varying_param_label: ['InflowBC_K05','InflowBC_K06','InflowBC_K07','InflowBC_K08','InflowBC_K09','InflowBC_K10','InflowBC_K11','InflowBC_K12','InflowBC_K13','InflowBC_K14','InflowBC_K15','InflowBC_K16','InflowBC_K17','InflowBC_K18','InflowBC_K19','InflowBC_K20','InflowBC_K056','InflowBC_K125','InflowBC_K195'] # folder_ID
  strata_labels: ['PHY','BC']
  state_vector_labels: ['coord_x','u'] 
  N_samples_per_stratum: {'N_coll': 1000}
  L: 1.0
  c: 1.0
  initial_time: 0.0
  N_time_step: 51
  time_step: 0.02
  total_time: 1
 

# pde_param:
#   name: 'linear_advection'
#   k: {}

branch1:
  neuralNet:
    architecture : "MLP"  # "Mlp" or "Modified MLP" or "Modified Deeponet"
    in_dim : 51  # 'm_input_sensors' (inflow condition u(0,t) per timestep)
    num_layers : 3
    hidden_dim : 50
    out_dim : 128 
    activation : "tanh" # "swish", "tanh", "gelu"
    xavier_init : true

branch2:
  neuralNet:
    architecture : "MLP"  # "Mlp" or "Modified MLP" or "Modified Deeponet"
    in_dim : 1000  # 'm_input_sensors' (inflow condition u(0,t) per timestep)
    num_layers : 3
    hidden_dim : 50
    out_dim : 128 
    activation : "tanh" # "swish", "tanh", "gelu"
    xavier_init : true

branches_control:
  branch_list_ID: ['branch1', 'branch2']
  branch_input_ID: ['InflowBC_K','phi'] 

trunk1:
  neuralNet:
    architecture : "MLP"  # "Mlp" or "Modified MLP" or "Modified Deeponet"
    in_dim : 2
    num_layers : 3
    hidden_dim : 50
    out_dim : 128 
    activation : "tanh" # "swish", "tanh", "gelu"
    xavier_init : true

trunk_control:
  trunk_list_ID: ['trunk1']
  trunk_input_ID: ['xt'] 
  
  
train: 
  n_training_param: 6
  training_param: [0.5,0.9,1.2,1.5,1.8,2.0] # parameter k
  training_param_label: ['InflowBC_K05','InflowBC_K09','InflowBC_K12','InflowBC_K15','InflowBC_K18','InflowBC_K20']
  adam_steps: 50000
  lbfgs_steps: 0
  stop_iter: -1 
  batch_size_coll: 512
  batch_dfraction:  # Specific decimal fraction with respect to total data in boundary conditions {Inlet, Wall, Outlet}, initial condition and validation ds
    data: 1.0
    ic: 1.0
    bc: 1.0
    val: 1.0
    bc_fixed: 1.0
    ic_fixed: 1.0
  data_extraction: 
     mode: 'random' # 'none', 'random'
     decimal_fraction: 0.01 # mode: 'none', 'random'

test: 
  n_test_param: 9
  test_param: [0.5,0.9,1.2,1.5,1.8,2.0, 0.56,1.25,1.95] # parameter k
  test_param_label: ['InflowBC_K05','InflowBC_K09','InflowBC_K12','InflowBC_K15','InflowBC_K18','InflowBC_K20', 'InflowBC_K056','InflowBC_K125','InflowBC_K195']
  batch_size: 10000
  t_values: [0.0,0.5,1.0,0.35,0.53,0.87]
 

optim1:
  optimizer : 'Adam'
  beta1: 0.9
  beta2: 0.999
  eps: 1.0e-8
  learning_rate: 1.0e-3
  exponential_decay:
    enabled: false
    decay_rate: 0.95  
    decay_steps: 3000

optim2:
  optimizer : 'LBFGS'
  max_iter: 50 
  max_eval: 50
  history_size: 50
  learning_rate : 1.0

tl: # transfer learning
  stop_total_loss: -1


fourier_emb:  # Fourier Features Embedding
  enabled: false
  stddev: 1.0
  embed_dim: 128


loss_terms: ["phy","bc", "ic", "data"]
lambda_weights_init: [1.0, 1.0, 1.0, 1.0]

loss_balancing:
  scheme: 'no_weights'
  enabled: false
  
  # update_step: 500
# lambda_weights_init: [1.0, 1.0, 1.0, 1.0]
 
  # scheme: 'data_guided_weights'
  # enabled: true
  # update_step: 500
  
#   scheme: 'fixed_weights'
#   enabled: true
#   update_step: 500
# lambda_weights_init: [1.0, 100.0, 100.0, 100.0]
  

  # scheme: 'ntk_guided_weights'
  # enabled: true
  # type: 'moderate_local_NTK_weights' # 'global_NTK_weights', 'local_NTK_weights', 'moderate_local_NTK_weights'
  # update_step: 500


# loss_balancing:  # Grad Norm - Self adaptive learning rate annealing algorithm 
  # enabled: false
  # scheme: "grad_norm"
  # momentum: 0.9
  # update_step: 1000
  

logging: 
  log_every_steps : 500
  monitoring_resources: true


seed: 42 
